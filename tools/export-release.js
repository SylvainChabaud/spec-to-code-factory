#!/usr/bin/env node

/**
 * Export Release Script
 *
 * Exports only the deliverable project files, excluding factory infrastructure.
 * Generates an enriched README.md from specs.
 *
 * Usage:
 *   node tools/export-release.js [--output <dir>] [--dry-run] [--validate]
 *
 * Part of Gate 5 validation.
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const ROOT_DIR = path.resolve(__dirname, '..');

// ============================================================================
// CONFIGURATION - EXCLUSION APPROACH (factory paths are fixed and known)
// ============================================================================

/**
 * Factory infrastructure paths - these are ALWAYS excluded
 * Everything else at root level is considered deliverable
 */
const FACTORY_EXCLUSIONS = {
  // Factory directories (always excluded)
  directories: [
    '.claude',           // Claude Code config (agents, skills, rules, hooks)
    'docs',              // All specs, planning, ADR, QA, release docs
    'tools',             // Validation scripts, gate checks
    'templates',         // Document templates
    'input',             // Requirements input
    'node_modules',      // Dependencies (reinstalled by user)
    'dist',              // Build output (regenerated)
    '.git',              // Git history
    'release',           // Previous exports
    'coverage',          // Test coverage reports (regenerated)
  ],

  // Factory files at root (always excluded)
  files: [
    'CLAUDE.md',
    'output.md',
    '.env',              // Secrets - never export (only .env.example)
    'package-lock.json', // Regenerated by npm install
  ],

  // Patterns excluded everywhere
  patterns: [
    '*.log',
    '.DS_Store',
    'Thumbs.db',
  ]
};

// Files to read for README generation
const SPEC_SOURCES = {
  brief: 'docs/brief.md',
  api: 'docs/specs/api.md',
  domain: 'docs/specs/domain.md',
  system: 'docs/specs/system.md',
  adr: 'docs/adr'
};

// ============================================================================
// HELPERS
// ============================================================================

function log(message, type = 'info') {
  const prefix = {
    info: '\x1b[36m[INFO]\x1b[0m',
    success: '\x1b[32m[OK]\x1b[0m',
    warn: '\x1b[33m[WARN]\x1b[0m',
    error: '\x1b[31m[ERROR]\x1b[0m'
  };
  console.log(`${prefix[type] || prefix.info} ${message}`);
}

function readFileIfExists(filePath) {
  const fullPath = path.join(ROOT_DIR, filePath);
  if (fs.existsSync(fullPath)) {
    return fs.readFileSync(fullPath, 'utf-8');
  }
  return null;
}

function extractSection(content, sectionName) {
  if (!content) return '';

  const regex = new RegExp(`## ${sectionName}[\\s\\S]*?(?=\\n## |$)`, 'i');
  const match = content.match(regex);
  return match ? match[0].trim() : '';
}

function extractBriefSummary(briefContent) {
  if (!briefContent) return 'A project generated by Spec-to-Code Factory.';

  const summary = extractSection(briefContent, 'Résumé exécutif');
  if (summary) {
    // Remove the heading, keep only content
    return summary.replace(/^## Résumé exécutif\s*/i, '').trim();
  }

  // Fallback: first paragraph after title
  const lines = briefContent.split('\n').filter(l => l.trim() && !l.startsWith('#'));
  return lines.slice(0, 3).join('\n');
}

function extractUsageFromApi(apiContent) {
  if (!apiContent) return 'See API documentation for usage details.';

  // Extract examples from each command
  const examples = [];
  const commandRegex = /### (\w+ \w+)[\s\S]*?```bash([\s\S]*?)```/g;
  let match;

  while ((match = commandRegex.exec(apiContent)) !== null) {
    const cmdName = match[1];
    const cmdExamples = match[2].trim().split('\n').slice(0, 2).join('\n');
    examples.push(`### ${cmdName}\n\`\`\`bash\n${cmdExamples}\n\`\`\``);
  }

  return examples.length > 0 ? examples.join('\n\n') : 'See API specs for detailed usage.';
}

function extractConfigSection(apiContent, envContent) {
  const sections = [];

  // Extract from API if present
  if (apiContent) {
    const authSection = extractSection(apiContent, 'Authentification');
    if (authSection) {
      sections.push(authSection.replace(/^## Authentification/i, '### Environment Variables'));
    }
  }

  // Add .env.example reference
  if (envContent) {
    sections.push('### Environment Setup\n\nCopy `.env.example` to `.env` and configure your values:\n\n```bash\ncp .env.example .env\n```');
  }

  return sections.join('\n\n') || 'No specific configuration required.';
}

function extractArchitectureFromDomain(domainContent) {
  if (!domainContent) return 'See domain specs for architecture details.';

  const contexts = extractSection(domainContent, 'Bounded Contexts');
  const entities = extractSection(domainContent, 'Entités');
  const services = extractSection(domainContent, 'Domain Services');

  const parts = [];

  if (contexts) {
    // Extract the ASCII diagram
    const diagramMatch = contexts.match(/```[\s\S]*?```/);
    if (diagramMatch) {
      parts.push('### Bounded Contexts\n' + diagramMatch[0]);
    }
  }

  if (services) {
    parts.push(services);
  }

  return parts.join('\n\n') || 'See domain specification for architecture details.';
}

function formatAdrForReadme(adrContent, filename) {
  if (!adrContent) return null;

  // Extract title and decision
  const titleMatch = adrContent.match(/^# (.+)$/m);
  const title = titleMatch ? titleMatch[1] : filename;

  const statusMatch = adrContent.match(/## Statut\s*\n\s*(\w+)/i);
  const status = statusMatch ? statusMatch[1] : 'Unknown';

  const decisionSection = extractSection(adrContent, 'Decision');
  const decision = decisionSection
    .replace(/^## Decision\s*/i, '')
    .split('\n')
    .slice(0, 5)
    .join('\n');

  return `### ${title}\n\n**Status**: ${status}\n\n${decision}`;
}

function loadAdrFiles() {
  const adrDir = path.join(ROOT_DIR, SPEC_SOURCES.adr);
  if (!fs.existsSync(adrDir)) return [];

  const files = fs.readdirSync(adrDir).filter(f => f.endsWith('.md'));
  return files.map(f => {
    const content = fs.readFileSync(path.join(adrDir, f), 'utf-8');
    return formatAdrForReadme(content, f);
  }).filter(Boolean);
}

// ============================================================================
// README GENERATION
// ============================================================================

function generateEnrichedReadme() {
  log('Generating enriched README.md...');

  // Load spec files
  const brief = readFileIfExists(SPEC_SOURCES.brief);
  const api = readFileIfExists(SPEC_SOURCES.api);
  const domain = readFileIfExists(SPEC_SOURCES.domain);
  const envExample = readFileIfExists('.env.example');

  // Extract package info
  const pkg = JSON.parse(fs.readFileSync(path.join(ROOT_DIR, 'package.json'), 'utf-8'));

  // Build sections
  const projectName = pkg.name.split('-').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ');
  const briefSummary = extractBriefSummary(brief);
  const usageSection = extractUsageFromApi(api);
  const configSection = extractConfigSection(api, envExample);
  const architectureSection = extractArchitectureFromDomain(domain);
  const adrSections = loadAdrFiles();

  // Build README
  const readme = `# ${projectName}

${briefSummary}

## Installation

\`\`\`bash
npm install
\`\`\`

## Quick Start

${usageSection}

## Configuration

${configSection}

## Architecture

${architectureSection}

${adrSections.length > 0 ? `## Technical Decisions\n\n${adrSections.join('\n\n---\n\n')}` : ''}

## Development

### Running tests

\`\`\`bash
npm test
\`\`\`

### Building

\`\`\`bash
npm run build
\`\`\`

### Preview (Remotion)

\`\`\`bash
npm run remotion:preview
\`\`\`

## License

${pkg.license || 'MIT'}

---

*Generated by Spec-to-Code Factory*
`;

  return readme;
}

// ============================================================================
// FILE COPYING
// ============================================================================

/**
 * Check if a path is factory infrastructure (should be excluded)
 */
function isFactoryPath(relativePath) {
  const normalized = relativePath.replace(/\\/g, '/');
  const parts = normalized.split('/');
  const firstPart = parts[0];
  const basename = path.basename(relativePath);

  // Check directory exclusions
  if (FACTORY_EXCLUSIONS.directories.includes(firstPart)) {
    return true;
  }

  // Check file exclusions at root
  if (parts.length === 1 && FACTORY_EXCLUSIONS.files.includes(basename)) {
    return true;
  }

  // Check patterns
  for (const pattern of FACTORY_EXCLUSIONS.patterns) {
    if (pattern.startsWith('*')) {
      const ext = pattern.slice(1);
      if (basename.endsWith(ext)) return true;
    } else if (basename === pattern) {
      return true;
    }
  }

  return false;
}

/**
 * Discover all deliverable files/directories (everything not excluded)
 */
function discoverDeliverables() {
  const deliverables = {
    directories: [],
    files: []
  };

  const entries = fs.readdirSync(ROOT_DIR, { withFileTypes: true });

  for (const entry of entries) {
    if (isFactoryPath(entry.name)) continue;

    if (entry.isDirectory()) {
      deliverables.directories.push(entry.name);
    } else {
      deliverables.files.push(entry.name);
    }
  }

  return deliverables;
}

function copyDirectory(src, dest) {
  if (!fs.existsSync(src)) return 0;

  fs.mkdirSync(dest, { recursive: true });
  let count = 0;

  const entries = fs.readdirSync(src, { withFileTypes: true });

  for (const entry of entries) {
    const srcPath = path.join(src, entry.name);
    const destPath = path.join(dest, entry.name);
    const relativePath = path.relative(ROOT_DIR, srcPath);

    if (isFactoryPath(relativePath)) continue;

    if (entry.isDirectory()) {
      count += copyDirectory(srcPath, destPath);
    } else {
      fs.copyFileSync(srcPath, destPath);
      count++;
    }
  }

  return count;
}

function copyFile(src, dest) {
  if (!fs.existsSync(src)) return false;

  const destDir = path.dirname(dest);
  fs.mkdirSync(destDir, { recursive: true });
  fs.copyFileSync(src, dest);
  return true;
}

// ============================================================================
// PACKAGE.JSON CLEANING
// ============================================================================

function cleanPackageJson(outputDir) {
  const pkgPath = path.join(outputDir, 'package.json');
  if (!fs.existsSync(pkgPath)) return;

  const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'));

  // Remove factory-specific scripts
  const factoryScripts = ['gate:check', 'validate', 'scan:secrets'];
  for (const script of factoryScripts) {
    delete pkg.scripts[script];
  }

  // Keep all dependencies (they're needed for the project)
  // Just clean up description if needed

  fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2));
  log('Cleaned package.json (removed factory scripts)');
}

/**
 * Clean .gitignore - remove factory-specific entries
 */
function cleanGitignore(outputDir) {
  const gitignorePath = path.join(outputDir, '.gitignore');
  if (!fs.existsSync(gitignorePath)) return;

  const content = fs.readFileSync(gitignorePath, 'utf-8');
  const lines = content.split('\n');

  // Patterns to remove (factory-specific)
  const factoryPatterns = [
    /^#.*[Ff]actory/,           // Comments mentioning factory
    /^docs\/factory/,            // docs/factory paths
    /^\.claude/,                 // .claude paths
    /^tools\//,                  // tools/ paths
    /^templates\//,              // templates/ paths
    /^input\//,                  // input/ paths
    /^CLAUDE\.md$/,              // CLAUDE.md
  ];

  const cleanedLines = lines.filter(line => {
    const trimmed = line.trim();
    // Keep empty lines and non-factory lines
    if (!trimmed) return true;
    return !factoryPatterns.some(p => p.test(trimmed));
  });

  // Remove trailing empty lines from factory section removal
  while (cleanedLines.length > 0 && cleanedLines[cleanedLines.length - 1].trim() === '') {
    cleanedLines.pop();
  }
  cleanedLines.push(''); // Ensure single trailing newline

  fs.writeFileSync(gitignorePath, cleanedLines.join('\n'));
  log('Cleaned .gitignore (removed factory entries)');
}

// ============================================================================
// MANIFEST GENERATION
// ============================================================================

function generateManifest(outputDir, files) {
  const manifest = {
    version: '1.0.0',
    exportedAt: new Date().toISOString(),
    factory: 'Spec-to-Code Factory',
    files: files,
    checksums: {}
  };

  // Generate simple checksums for key files
  const keyFiles = ['package.json', 'README.md', 'tsconfig.json'];
  for (const file of keyFiles) {
    const filePath = path.join(outputDir, file);
    if (fs.existsSync(filePath)) {
      const content = fs.readFileSync(filePath);
      // Simple hash for verification
      let hash = 0;
      for (let i = 0; i < content.length; i++) {
        hash = ((hash << 5) - hash) + content[i];
        hash = hash & hash;
      }
      manifest.checksums[file] = hash.toString(16);
    }
  }

  return manifest;
}

// ============================================================================
// VALIDATION
// ============================================================================

async function validateExport(outputDir) {
  log('Validating export...');

  const errors = [];
  const warnings = [];

  // Check required files exist
  const requiredFiles = ['package.json', 'tsconfig.json', 'README.md'];
  for (const file of requiredFiles) {
    if (!fs.existsSync(path.join(outputDir, file))) {
      errors.push(`Missing required file: ${file}`);
    }
  }

  // Check required directories exist
  const requiredDirs = ['src'];
  for (const dir of requiredDirs) {
    if (!fs.existsSync(path.join(outputDir, dir))) {
      errors.push(`Missing required directory: ${dir}/`);
    }
  }

  // Check no factory files leaked
  const factoryPatterns = [
    'docs/brief.md',
    'docs/scope.md',
    'docs/specs',
    'docs/planning',
    'docs/adr',
    'tools/gate-check.js',
    'tools/factory-state.js',
    '.claude/agents',
    '.claude/skills',
    'templates',
    'CLAUDE.md'
  ];

  for (const pattern of factoryPatterns) {
    if (fs.existsSync(path.join(outputDir, pattern))) {
      errors.push(`Factory file leaked into export: ${pattern}`);
    }
  }

  // Check package.json is valid
  try {
    const pkg = JSON.parse(fs.readFileSync(path.join(outputDir, 'package.json'), 'utf-8'));
    if (!pkg.name) warnings.push('package.json missing name');
    if (!pkg.main) warnings.push('package.json missing main entry');
  } catch (e) {
    errors.push('package.json is invalid JSON');
  }

  return { errors, warnings };
}

// ============================================================================
// MAIN
// ============================================================================

async function main() {
  const args = process.argv.slice(2);

  const outputArg = args.indexOf('--output');
  const outputDir = outputArg !== -1 && args[outputArg + 1]
    ? path.resolve(args[outputArg + 1])
    : path.join(ROOT_DIR, 'release');

  const dryRun = args.includes('--dry-run');
  const validateOnly = args.includes('--validate');

  console.log('\n=== Export Release ===\n');
  log(`Output directory: ${outputDir}`);
  log(`Dry run: ${dryRun}`);
  log(`Method: Exclusion-based (auto-discover deliverables)`);

  if (validateOnly && fs.existsSync(outputDir)) {
    const { errors, warnings } = await validateExport(outputDir);

    for (const w of warnings) log(w, 'warn');
    for (const e of errors) log(e, 'error');

    if (errors.length > 0) {
      log(`Validation failed with ${errors.length} error(s)`, 'error');
      process.exit(1);
    }

    log('Validation passed!', 'success');
    process.exit(0);
  }

  // Auto-discover deliverables (everything not in FACTORY_EXCLUSIONS)
  const deliverables = discoverDeliverables();

  console.log('\n--- Discovered Deliverables ---');
  log(`Directories: ${deliverables.directories.join(', ') || '(none)'}`);
  log(`Files: ${deliverables.files.join(', ') || '(none)'}`);
  console.log('');

  // Clean output directory
  if (fs.existsSync(outputDir) && !dryRun) {
    fs.rmSync(outputDir, { recursive: true });
    log('Cleaned existing output directory');
  }

  if (!dryRun) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  const exportedFiles = [];

  // Copy discovered directories
  for (const dir of deliverables.directories) {
    const srcDir = path.join(ROOT_DIR, dir);
    const destDir = path.join(outputDir, dir);

    if (dryRun) {
      log(`Would copy directory: ${dir}/`);
    } else {
      const count = copyDirectory(srcDir, destDir);
      log(`Copied ${dir}/ (${count} files)`, 'success');
      exportedFiles.push({ type: 'directory', path: dir, files: count });
    }
  }

  // Copy discovered files
  for (const file of deliverables.files) {
    const srcFile = path.join(ROOT_DIR, file);
    const destFile = path.join(outputDir, file);

    if (dryRun) {
      log(`Would copy file: ${file}`);
    } else {
      copyFile(srcFile, destFile);
      log(`Copied ${file}`, 'success');
      exportedFiles.push({ type: 'file', path: file });
    }
  }

  // Generate enriched README
  const readme = generateEnrichedReadme();

  if (dryRun) {
    log('Would generate README.md');
    console.log('\n--- README Preview ---\n');
    console.log(readme.slice(0, 1000) + '\n...[truncated]...\n');
  } else {
    fs.writeFileSync(path.join(outputDir, 'README.md'), readme);
    log('Generated enriched README.md', 'success');
    exportedFiles.push({ type: 'generated', path: 'README.md' });
  }

  // Clean package.json
  if (!dryRun) {
    cleanPackageJson(outputDir);
  }

  // Clean .gitignore
  if (!dryRun) {
    cleanGitignore(outputDir);
  }

  // Generate manifest
  if (!dryRun) {
    const manifest = generateManifest(outputDir, exportedFiles);
    fs.writeFileSync(
      path.join(outputDir, 'release-manifest.json'),
      JSON.stringify(manifest, null, 2)
    );
    log('Generated release-manifest.json', 'success');
  }

  // Validate
  if (!dryRun) {
    const { errors, warnings } = await validateExport(outputDir);

    console.log('\n--- Validation ---\n');
    for (const w of warnings) log(w, 'warn');
    for (const e of errors) log(e, 'error');

    if (errors.length > 0) {
      log(`Export completed but validation failed with ${errors.length} error(s)`, 'error');
      process.exit(1);
    }
  }

  console.log('\n=== Summary ===\n');
  log(`Exported ${exportedFiles.length} items to ${outputDir}`, 'success');

  if (!dryRun) {
    console.log('\n╔════════════════════════════════════════════════════════════════╗');
    console.log('║  ✅ PROJET LIVRABLE PRÊT                                       ║');
    console.log('║                                                                 ║');
    console.log('║  Le dossier release/ contient votre projet final.              ║');
    console.log('║  Copiez son contenu vers votre repo de destination.            ║');
    console.log('╚════════════════════════════════════════════════════════════════╝');
    console.log('');
    log('Pour utiliser votre projet :', 'info');
    console.log('');
    console.log('  # Option 1 : Copier vers un nouveau repo');
    console.log('  cp -r release/ ../mon-projet/');
    console.log('  cd ../mon-projet && git init && npm install');
    console.log('');
    console.log('  # Option 2 : Tester localement');
    console.log('  cd release && npm install && npm test && npm run build');
    console.log('');
  }

  process.exit(0);
}

main().catch(err => {
  log(err.message, 'error');
  process.exit(1);
});
